{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries"
      ],
      "metadata": {
        "id": "xFBKHBr7zY-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Ensure CUDA is available, else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "I7Ln6MJVfoyE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load data\n"
      ],
      "metadata": {
        "id": "ltwGk4Az1rF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/zhouhaoyi/ETDataset/raw/main/ETT-small/ETTm1.csv'\n",
        "data = pd.read_csv(url)\n",
        "print(data.head())\n",
        "\n",
        "features = ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']\n",
        "data = data[features]\n",
        "\n",
        "data_values = data.values\n",
        "print(\"Shape of the data:\", data_values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yri5go2zztA4",
        "outputId": "393b0aca-9b31-4ad2-de36-bd5daff06ddf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
            "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
            "1  2016-07-01 00:15:00  5.760  2.076  1.492  0.426  4.264  1.401  30.459999\n",
            "2  2016-07-01 00:30:00  5.760  1.942  1.492  0.391  4.234  1.310  30.038000\n",
            "3  2016-07-01 00:45:00  5.760  1.942  1.492  0.426  4.234  1.310  27.013000\n",
            "4  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
            "Shape of the data: (69680, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "crete sequence out of data"
      ],
      "metadata": {
        "id": "uiEvbs9y1xKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "step_size = 10\n",
        "num_features = 6  # Number of input features (HUFL, HULL, MUFL, MULL, LUFL, LULL)\n",
        "\n",
        "# Function to create input/output sequences\n",
        "def create_sequences(data, seq_length, step):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    for i in range(0, len(data) - seq_length, step):\n",
        "        inputs.append(data[i:i + seq_length, :-1])  # All features except 'OT'\n",
        "        outputs.append(data[i + seq_length - 1, -1])  # 'OT' as the target\n",
        "    return np.array(inputs), np.array(outputs)\n"
      ],
      "metadata": {
        "id": "7vyQIJ1Uzs-K"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sequences\n",
        "X, y = create_sequences(data_values, sequence_length, step_size)\n",
        "print(\"Shape of input sequences (X):\", X.shape)  # (num_samples, 100, 6)\n",
        "print(\"Shape of output sequences (y):\", y.shape)  # (num_samples,)\n",
        "\n",
        "# Split data into training and validation sets (80-20 split)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_val = X[:train_size], X[train_size:]\n",
        "y_train, y_val = y[:train_size], y[train_size:]\n",
        "\n",
        "# Display shapes\n",
        "print(\"Training input shape:\", X_train.shape)\n",
        "print(\"Validation input shape:\", X_val.shape)\n",
        "print(\"Training output shape:\", y_train.shape)\n",
        "print(\"Validation output shape:\", y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aOZZHaNzs7x",
        "outputId": "58abc1e4-5384-4fce-a53e-42fe29092bfc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input sequences (X): (6958, 100, 6)\n",
            "Shape of output sequences (y): (6958,)\n",
            "Training input shape: (5566, 100, 6)\n",
            "Validation input shape: (1392, 100, 6)\n",
            "Training output shape: (5566,)\n",
            "Validation output shape: (1392,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KeTDN5J1znqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional Encoding\n"
      ],
      "metadata": {
        "id": "1oSU-GLW15LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.encoding = torch.zeros(max_len, d_model).to(device)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1).to(device)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)).to(device)\n",
        "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
        "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.encoding = self.encoding.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.encoding[:, :x.size(1), :]\n"
      ],
      "metadata": {
        "id": "aWmUvkmqY2yv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seq-to-seq transformer"
      ],
      "metadata": {
        "id": "Hs4GzdoP18In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_len):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "\n",
        "        # Embedding layers\n",
        "        self.encoder_embedding = nn.Linear(input_dim, d_model).to(device)\n",
        "        self.decoder_embedding = nn.Linear(output_dim, d_model).to(device)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_len=max_seq_len).to(device)\n",
        "\n",
        "        # Encoder and Decoder\n",
        "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers,\n",
        "                                          num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward).to(device)\n",
        "\n",
        "        # Output projection layer\n",
        "        self.output_layer = nn.Linear(d_model, output_dim).to(device)\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
        "        return mask.to(device)\n",
        "\n",
        "    def forward(self, src, tgt, tgt_mask=None):\n",
        "        # Pass through encoder embedding and positional encoding\n",
        "        src = self.encoder_embedding(src)\n",
        "        src = self.positional_encoding(src)\n",
        "\n",
        "        # Pass through decoder embedding and positional encoding\n",
        "        tgt = self.decoder_embedding(tgt)\n",
        "        tgt = self.positional_encoding(tgt)\n",
        "\n",
        "        # Transformer forward pass\n",
        "        transformer_output = self.transformer(src.transpose(0, 1), tgt.transpose(0, 1), tgt_mask=tgt_mask)\n",
        "\n",
        "        # Project back to original output dimension\n",
        "        output = self.output_layer(transformer_output)\n",
        "\n",
        "        return output.transpose(0, 1)\n"
      ],
      "metadata": {
        "id": "VLG7z4ntY8yB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train test split"
      ],
      "metadata": {
        "id": "orQV06R82ALY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming input sequences and target sequences are already prepared as tensors\n",
        "# Replace these with actual data loading\n",
        "train_data = TensorDataset(torch.randn(1000, 100, 6), torch.randn(1000, 100, 1))\n",
        "val_data = TensorDataset(torch.randn(200, 100, 6), torch.randn(200, 100, 1))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)\n"
      ],
      "metadata": {
        "id": "C7VYWHVyY_tV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop"
      ],
      "metadata": {
        "id": "yV108TRu2CGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in train_loader:\n",
        "        # Move data to device\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Prepare target inputs and labels (shifted by one position for auto-regression)\n",
        "        tgt_input = tgt[:, :-1]  # Input to the decoder (except last step)\n",
        "        tgt_output = tgt[:, 1:]   # Target output sequence (except first step)\n",
        "\n",
        "        # Generate subsequent mask for the decoder\n",
        "        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(src, tgt_input, tgt_mask=tgt_mask)\n",
        "\n",
        "        # Ensure output matches target shape\n",
        "        if output.shape[1] != tgt_output.shape[1]:\n",
        "            output = output[:, :tgt_output.shape[1], :]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1, tgt_output.size(-1)))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "# Validation function\n",
        "def evaluate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in val_loader:\n",
        "            # Move data to device\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            tgt_input = tgt[:, :-1]  # Input to the decoder (except last step)\n",
        "            tgt_output = tgt[:, 1:]   # Target output sequence (except first step)\n",
        "\n",
        "            tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
        "\n",
        "            output = model(src, tgt_input, tgt_mask=tgt_mask)\n",
        "\n",
        "            # Ensure output matches target shape\n",
        "            if output.shape[1] != tgt_output.shape[1]:\n",
        "                output = output[:, :tgt_output.shape[1], :]  # Trim or pad as necessary\n",
        "\n",
        "            loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1, tgt_output.size(-1)))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)\n"
      ],
      "metadata": {
        "id": "ZWzxiWB3ZC-e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wF7Z-GJg2EXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "input_dim = 6\n",
        "output_dim = 1\n",
        "d_model = 64\n",
        "nhead = 4\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dim_feedforward = 256\n",
        "max_seq_len = 100\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "model = Seq2SeqTransformer(input_dim, output_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_len).to(device)\n",
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1RFbtvhZIij",
        "outputId": "fd5f7656-73bc-4d6f-f682-a42dda3a6563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 1.1732, Val Loss: 1.0007\n",
            "Epoch 2/10, Train Loss: 1.0422, Val Loss: 0.9940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot of loss"
      ],
      "metadata": {
        "id": "qFXk2sst2H97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training and validation losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(val_losses, label='Validation Loss', color='orange')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PNPiW3Escz76"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}